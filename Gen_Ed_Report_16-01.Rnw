%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stylish Article
% LaTeX Template
% Version 2.1 (1/10/15)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Mathias Legrand (legrand.mathias@gmail.com)
% With extensive modifications by:
% Vel (vel@latextemplates.com)
%
% Modified for General Education at Ferris State University
% by Dr. Clifton Franklund (CliftonFranklund@ferris.edu)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left
\usepackage[english]{babel}         % Specify a different language here - english by default
\usepackage{lipsum}                 % Required to insert dummy text. To be removed otherwise
\usepackage{fancyhdr}               % Required to put the logo on the top of the first page
\usepackage{float}                  % Extra help with figures and tables
\usepackage{caption}                % Helps to format captions
\captionsetup[table]{skip=3pt}      % Spacing after caption
\usepackage{enumitem}               % Tightening lists
\setlist[itemize]{itemsep=0mm}      % Tightening lists
\usepackage[style=authoryear,doi=false,isbn=false,url=false,natbib=true,backend=biber]{biblatex}
\bibliography{references}           % Point to the bibtex bibliography file
\renewbibmacro{in:}{}               % Get rid of "in:" in journal reference citations

%----------------------------------------------------------------------------------------
%	COLUMNS
%----------------------------------------------------------------------------------------

\setlength{\columnsep}{0.55cm}      % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt}       % Width of the border around the abstract

%----------------------------------------------------------------------------------------
%	COLORS
%----------------------------------------------------------------------------------------

\definecolor{color1}{RGB}{0,0,0}         % Color of the article title (black)
\definecolor{color2}{RGB}{255,255,255}   % Section heading text color (white)
\definecolor{color3}{RGB}{178,34,34}     % Color of the boxes behind the abstract and headings (firebrick)

%----------------------------------------------------------------------------------------
%	HYPERLINKS
%----------------------------------------------------------------------------------------

\usepackage{hyperref}               % Required for hyperlinks
\hypersetup{hidelinks,colorlinks,breaklinks=true,urlcolor=color3,citecolor=color3,linkcolor=color1,bookmarksopen=false,pdftitle={Title},pdfauthor={Author}}

%----------------------------------------------------------------------------------------
%	NO SECTION NUMBERS
%----------------------------------------------------------------------------------------
\setcounter{secnumdepth}{0}
\setlength{\belowcaptionskip}{10pt}

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\JournalInfo{General Education Assessment}     % Report information
\Archive{Report 16(1) --- July 2016}           % Report identifier and date)

\PaperTitle{Meta-Analysis of Student Achievement on Natural Science FLO SCI1 in a 200-Level Biology Course} % Article title

\Authors{Dr. Clifton Franklund\textsuperscript{1}} % Authors
\affiliation{\textsuperscript{1}\textit{General Education Coordinator, Ferris State University}} % Author affiliation

\Keywords{Meta-Analysis --- Forest plot --- Natural Sciences --- Scientific concepts}
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{This report is a proof-of-concept for the proposed General Education assessment strategy at Ferris State University. Course-level student assessment data was gathered using TracDat and de-identified. The clean and tidy data set was used to generate this report using the R statistical programming language. Thirteen semesters of student performance on a lecture exam were used to evaluate student competency on Ferris Learning Outcome (FLO) SCI1. A meta-analysis of these data demonstrated that  performance was very near the criterion of success. There was substantial variation in enrollment and course performance over the time span examined The utility of reports like these to analyze, distribute, and act up General Education assessment data will be investigated using faculty focus groups in the fall of 2016.~}

%----------------------------------------------------------------------------------------

\begin{document}

\flushbottom % Makes all text pages the same height

\maketitle % Print the title and abstract box

\tableofcontents % Print the contents section

% Set up the first page to have the Ferris logo in the left
\fancypagestyle{firststyle}
{
	\fancyhf{}
	\fancyhead[L]{\includegraphics[height=0.55cm]{./art/logo.png}}
}
\thispagestyle{firststyle}


%----------------------------------------------------------------------------------------
%	INITIALIZE R PARAMETERS FOR THIS DOCUMENT
%----------------------------------------------------------------------------------------

<<packages, echo=FALSE, message=FALSE, warning=FALSE>>=

#----------------------------------------------------------------------------------------
#	INSTALL PACKAGES
#----------------------------------------------------------------------------------------

packages<-function(x){
        x<-as.character(match.call()[[2]])
        if (!require(x,character.only=TRUE)){
                install.packages(pkgs=x,repos="http://cran.r-project.org")
                require(x,character.only=TRUE)
        }
}
packages(modeest)       # calculate mode
packages(moments)       # calculate skew, kurtosis, etc.
packages(weights)       # calculate weighted t-test
packages(papeR)		# making LaTeX from some outputs
packages(xtable)        # make nice tables of data
packages(dplyr)         # handling tidy data neatly
packages(ggplot2)       # make pretty pictures
packages(forestplot)    # present meta-analysis
@

<<functions, echo=FALSE, message=FALSE, warning=FALSE>>=

#----------------------------------------------------------------------------------------
#	DEFINE FUNCTIONS
#----------------------------------------------------------------------------------------

# Adds legends above figures (used for barplot)
add_legend <- function(...) {
  opar <- par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0),
    mar=c(0, 0, 0, 0), new=TRUE)
  on.exit(par(opar))
  plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')
  legend(...)
}

#  Computes the variance of a weighted mean following Cochran 1977 definition
#  Code found online at:
#  http://stats.stackexchange.com/questions/25895/computing-standard-error-in-weighted-mean-estimation
weighted.var.se <- function(x, w, na.rm=FALSE)
	{
	if (na.rm) { w <- w[i <- !is.na(x)]; x <- x[i] }
	n = length(w)
	xWbar = weighted.mean(x,w,na.rm=na.rm)
	wbar = mean(w)
	out = sqrt(n/((n-1)*sum(w)^2)*(sum((w*x-wbar*xWbar)^2)-2*xWbar*sum((w-wbar)*(w*x-wbar*xWbar))+xWbar^2*sum((w-wbar)^2)))
	low = xWbar-(out*1.96)
	high = xWbar+(out*1.96)
	myOutput <- c(mean=format(round(xWbar,2),nsmall=2),low=format(round(low,2),nsmall=2),high=format(round(high,2),nsmall=2))
	return(myOutput)
}

# Computes omega squared (effect size) for an ANOVA analysis
omega_sq <- function(aovm){
    sum_stats <- summary(aovm)[[1]]
    SSm <- sum_stats[["Sum Sq"]][1]
    SSr <- sum_stats[["Sum Sq"]][2]
    DFm <- sum_stats[["Df"]][1]
    MSr <- sum_stats[["Mean Sq"]][2]
    W2 <- (SSm-DFm*MSr)/(SSm+SSr+MSr)
    return(W2)
}

@

<<data, echo=FALSE, message=FALSE, warning=FALSE>>=

#----------------------------------------------------------------------------------------
#	LOAD DATA
#----------------------------------------------------------------------------------------

myData <- read.csv("BIOL200Data.csv", row.names = NULL, stringsAsFactors = FALSE)
@


%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

%---------------------------
%>>>>>>>> EPIGRAPH  <<<<<<<<
%---------------------------
\begin{quote}
\begin{center}
\textit{Assessment is not a spreadsheet; \\ it's a conversation. --- Irmeli Halinen}
\end{center}
\end{quote}

%---------------------------
%>>>>>> INTRODUCTION  <<<<<<
%---------------------------
\section{Introduction} % The \section*{} command stops section numbering
%\addcontentsline{toc}{section}{Introduction} % Adds this section to the table of contents

This report is an actual analysis of real course-level assessment data from a 200-level Biology course. However, its primary purpose is to serve as a proof-of-concept for the new General Education assessment process at Ferris State University. Assessment is perhaps best viewed as a scholarly activity that is focused upon programmatic improvement. Such scholarly work should be built upon, and contribute to, the relevant professional literature \citep{Weimer2015}. To emphasize that reality, this report is formatted in the form of a journal article. This report, and ones like it, will be authored, published, and cited in future work to support the development and improvement of the General Education program at Ferris.

Many different approaches can be used to assess a General Education program; direct and indirect assessment can take place at the course, program, or institutional levels. The structure, strengths and weaknesses of each of these are highlighted elsewhere \citep{Allen2006a}. Regardless of the approach used, a quality program evaluation must possess five key attributes: utility, feasibility, propriety, accuracy, and accountability \citep{Yarbrough2011}. Both this report, and the assessment processes underlying it, are designed to satisfy these requirements.

% PROCESS FIGURE INSERTED HERE
\begin{figure*}[htb]\centering % Using \begin{figure*} makes the figure take up the entire width of the page
\includegraphics[width=\textwidth]{./art/process}
\protect\caption{A diagram illustrating the flow of data from initial collection to storage, access, and use. This process constitutes "closing the loop" on assessing General Education competencies. The blue boxes highlight steps with direct faculty involvement; the red boxes indicate processes carried out by the General Education Coordinator. The golden region indicates the files that are publicly available on the Open Science Framework.}
\label{fig:process}
\end{figure*}

The \textit{utility} of the assessment process is a measure of how useful it is to the relevant stakeholders. A broad sampling of our faculty are engaged in the section of assessment outcomes, collection of data, and interpretation of assessment findings. This involvement ensures that any results are viewed within an appropriate context, and increases their value for program evaluation. The automated nature of the data collection, aggregation, and analysis increases the \textit{feasibility} of this approach. Much of the reports must still be authored by the General Education Coordinator. However, having the data manipulations and analysis done automatically greatly simplifies the task. \textit{Propriety} speaks to the ethical use of the data and results. Every effort has been made to ensure that the identities of all students and faculty involved in these studies is protected. No personally identifiable information will ever be included in these results. Furthermore, the General Education assessment results exist solely for the improvement of the General Education program -- the results will \underline{never} be used for the evaluation of specific courses or instructional personnel. The \textit{accuracy} of these reports is improved by the very nature of the analysis and reporting used. Meta-analyses \citep{Borenstein2011} are used to compare groups of related assessment results. This approach can account for variation in scoring and student ability between courses and provide an a more realistic overview of student competencies. The range of meta-data collected in addition to student evaluations will permit the testing of a variety of research hypotheses. This report is also a form of reproducible research \citep{Stodden2014}. This report is computationally reproducible because the code needed to manipulate the de-identified data, perform the analyses, and create the figures are included within the no-web (.Rnw) file itself. This approach was first described as "literate programming" in the 1980's \citep{Knuth1984}. The principle advantage to this approach is that anyone (at any time) can reproduce, critique, and extend these studies without needing to track down multiple documents, graphics files, and data sets. Finally, the \textit{accountability} of reports such as this one is safeguarded by the involvement of faculty in contextualizing the results. All reports will be shared with appropriate focus groups for their input. Their comments and recommendations for future actions will be summarized and included within the discussion section of each document.

The overall process employed in this assessment strategy is illustrated in Figure \ref{fig:process} and described in the Methods. As a proof-of-concept, \Sexpr{max(myData$Order)} semesters of student results from a 200-level Biology course are analyzed. A more typical analysis would be from a variety of courses (say from Biology, Chemistry, Physics, Geology, and Geography) to evaluate a specific FLO over a specific period of time.

%---------------------------
%>>>>>>>>> METHODS <<<<<<<<<
%---------------------------
\section{Methods}
%\addcontentsline{toc}{section}{Methods} % Adds this section to the table of contents

\subsection{Collection of assessment data}
Student performance on the first lecture exam in a 200-level Biology course was analyzed. The content assessed in all exams was biological diversity. However, the number and format of the questions used varied by semester. Individual student scores were collected using the new General Education Natural Sciences "scores" data workbook for \Sexpr{max(myData$Order)} semesters. Student scores were automatically converted to a rubric score by the workbook using the equivalencies shown in Table \ref{tab:convert}.

% CONVERSION TABLE INSERTED HERE
\begin{table}[hbt]
\caption{Conversion of percentages to rubric scores}
\centering
\begin{tabular}{c c c}
\textbf{Percent correct} & \textbf{Rubric} & \textbf{Interpretation}   \\
\hline
 0.0 to 49.9\%   &   0   &   Unsatisfactory                                \\
50.0 to 59.9\%   &   1   &   Beginning                                     \\
60.0 to 69.9\%   &   2   &   Developing                                    \\
70.0 to 84.9\%   &   3   &   Proficient                                    \\
85.0 to 100.0\%  &   4   &   Advanced                                      \\
\end{tabular}
\label{tab:convert}
\end{table}

These workbook files contain personally identifiable information (PII) and are, therefore, subject to FERPA regulations. For this reason, they are not directly shared. Instead, they are permanently housed within the Proof\_of\_Concept folder under Core Competency: Natural Sciences in TracDat.

\subsection{De-identification of student data}
Copies of the \Sexpr{max(myData$Order)} data files were downloaded from TracDat. An R aggregator script was used to read the data from these data sheets and concatenate it into one data set in a destructive process -- the downloaded copies were deleted in the process. Student names and identification numbers were redacted and each student's entry was given a unique eight-digit identifier - the Record.Key. These keys may be used for longitudinal studies in the future. The algorithm used is kept in an encrypted site and shared with \textit{no one}. The de-identified data set contains \Sexpr{length(myData$Order)} student entries and is formatted as a comma-delimited text file (BIOL200Data.csv).

\subsection{Data provenance}
Data provenance refers to a system that permits tracking of the origin, movement, modification, and utilization of data sets\citep{Buneman2001}. The provenance of General Education data will be explicitly declared to facilitate the reproducibility and extensibility of these studies.

\paragraph{Location of public website files}
All files related to this report can be found online at the Open Science Framework \citep{Nosek2012}. This site contains all of the files needed to reproduce this report from the de-identified data set. The site's url is \href{https://osf.io/t6u8m/}{https://osf.io/t6u8m/}.

\paragraph{Session information}
This report was written using RStudio \citep{Rstudio} and the R statistical programming language \citep{R}. These products are free to download for PC, Macintosh, and Linux operating systems. The following information pertains to the session parameters used to generate this report. If you have trouble reproducing this report, it may be due to different session parameters. You may contact \href{mailto:CliftonFranklund@ferris.edu}{Dr. Franklund} if you need assistance.

% SESSION INFO INSERTED HERE
<<Session, echo=FALSE, message=FALSE, comment=NA, results='asis'>>=
session <- utils::toLatex(sessionInfo(), locale=FALSE, citations=FALSE)
session
#toLatex(session)
@

\paragraph{Processing instructions}
This project produced a computationally reproducible assessment report (this document). Anyone wishing to recreate this report from the source document will need to install the following on their computer:
\begin{enumerate}
\item \href{https://www.r-project.org}{An installation of the R programming language}
\item \href{https://www.rstudio.com/products/rstudio/download3/}{ An installation of the RStudio IDE}
\item \href{https://www.latex-project.org/get/}{An installation of \LaTeX}
\end{enumerate}

The necessary source files include the de-identified data set (BIOL200Data.csv), no-web code file (Gen\_Ed\_Report\_16-01.Rnw), bibtex reference file (references.bib), and custom art file in the /art folder.

To process the files, you must first open the .Rnw file in RStudio. Click on the "Compile PDF" button in the menu bar. The resulting tex file (Gen\_Ed\_Report\_16-01.tex) must be further processed to create the citations and internal links. This is done by running PDFLaTeX on the .tex file, followed by biber, and then PDFLaTeX twice more. This report will be the resulting pdf file.

\paragraph{Citation of this work}
All of the de-identified data, analysis code, and documentation that constitute this report project may be freely used, modified, and shared. The code file, Gen\_Ed\_Report\_16-01.Rnw, was adapted from that of Matias Legrand. Like the original file, it is released under the Creative Commons \href{http://creativecommons.org/licenses/by-nc-sa/3.0/}{CC BY-NC-SA 3.0} license. The de-identified data set, BIOL200Data.csv, is released under the Creative Commons \href{https://creativecommons.org/publicdomain/zero/1.0/}{CC0 license}. All documentation, including README.md, Codebook.md, and this report, are released under the Creative Commons \href{https://creativecommons.org/licenses/by/4.0/}{CC-BY} licence. Any questions, comments, or suggestions may be sent to \href{mailto:CliftonFranklund@ferris.edu}{Dr. Franklund}.


%---------------------------
%>>>>>>>>> RESULTS <<<<<<<<<
%---------------------------
\section{Results}
This document itself is the primary result of the project. It will be shared with members of the General Education Committee, Academic Senate, and the Department of Biological Sciences at Ferris State University. Their comments and suggestions will be included in the Discussion.

% T-test calculation
<<ttest, echo=FALSE, message=FALSE, comment=NA, results='asis'>>=
scoreResults <- t.test(myData$SCI1, mu=2.6)
@

\subsection{Summary statistics}
A total of \Sexpr{length(myData$SCI1)} student performances on exam 1 were collected over \Sexpr{max(myData$Order)} semesters of instruction. Student scores were converted to rubric scores as described above. The overall average rubric score for all students and semesters was \Sexpr{round(mean(myData$SCI1),2)}. The mode and median scores were \Sexpr{round(mfv(myData$SCI1)[1],2)} and \Sexpr{round(median(myData$SCI1),2)}, respectively. The average was not statistically different from the threshold score for competence (2.6) as evaluated with a one-value, two-tailed t-test (t=\Sexpr{round(scoreResults$statistic,2)}, df=\Sexpr{round(scoreResults$parameter,2)}, p=\Sexpr{format(scoreResults$p.value, digits=2)}). The effect size for the difference between the average and the threshold was tiny (d=\Sexpr{round(scoreResults$statistic/sqrt(scoreResults$parameter),2)}). We can infer from this that the overall average rubric score is not practically different than the threshold score.
% HISTOGRAM FIGURE INSERTED HERE
\begin{figure}[h]\centering
<<histogram, echo=FALSE, message=FALSE, results='hide'>>=
distribution <- table(myData$SCI1)
pdf("./figure/histogram.pdf", width=3.0, height=4.0)
barplot(distribution, ylim=c(0,500), las=1, xlab="", ylab="Overall Frequency", axis.lty = 1, col="firebrick", cex.axis = 0.85, cex.lab = 0.85, cex.names=0.85)
mtext(side = 1, text = "Rubric Score on SCI1", line = 1.8, cex=0.85)
dev.off()
@
\includegraphics[width=\columnwidth,viewport = 0 20 216 240]{./figure/histogram}
\protect\caption{A histogram of the distribution of individual rubric score frequencies over all thirteen semesters.}
\label{fig:histogram}
\end{figure}

The distribution of all rubric scores is shown in Figure \ref{fig:histogram}. This distribution exhibited a moderate negative skew (skew = \Sexpr{round(skewness(myData$SCI1, na.rm = TRUE),2)}). This result may simply indicate that the teaching, materials, and student learning are all functioning well when the scores are viewed in aggregate. A total of \Sexpr{sum(myData$SCI1 >= 3)} students (\Sexpr{round(sum(myData$SCI1 >= 3)/length(myData$SCI1)*100,1)}\%) met or exceeded the competence threshold over the semesters investigated.

The distribution of rubric scores by semester is shown in Figure \ref{fig:barplot}. There are rather obvious differences in both the distribution of rubric scores and class sizes between semesters. A one-way ANOVA was used to compare the rubric scores by semester (Table \ref{tab:anova}). Unsurprisingly, there were statistically significant differences between semester scores. Semester of instruction, however, explained a relatively small amount of the overall variance ($\eta^2$ = \Sexpr{round(anova(lm(SCI1 ~ Semester, data = myData))[1,2]/sum(anova(lm(SCI1 ~ Semester, data = myData))[,2]),2)}).

% BARPLOT FIGURE INSERTED HERE
\begin{figure}[h]\centering
<<barplot, echo=FALSE, message=FALSE, results='hide'>>=
bySemester <- as.matrix(table(myData$SCI1,myData$Order))
bySemester <- bySemester[,ncol(bySemester):1]
semesterTotals <- apply(bySemester, 2, sum)
for(dummy in 1:ncol(bySemester)){
	bySemester[,dummy] <- bySemester[,dummy]/semesterTotals[dummy]*100
}
myLabels <- c("Fall 2015","Spring 2015","Fall 2014","Spring 2014","Fall 2013","Spring 2013","Fall 2012","Spring 2012","Fall 2011","Spring 2011","Fall 2010","Spring 2010","Fall 2009")
#col <- c("firebrick","red","yellow","aquamarine","darkgreen")
col <- c("#a50f15","#de2d26","#fb6a4a","#fcae91","#fee5d9")

pdf("./figure/barplot.pdf", width=4.0, height=4)
par(mar=c(4,8,3,2)+0.1)
barplot(as.matrix(bySemester),
	col=col,
	horiz = TRUE,
	xlab="",
	ylab="",
	names.arg=myLabels,
	xlim=c(0,100),
	las=1,
	cex.axis = 0.75,
	cex.lab=0.75,
	cex.names = 0.75)
mtext("Relative Frequency of Rubric Scores",side=1,line=2, cex = 0.75)
mtext("Semester",side=2,line=5, cex = 0.75)
add_legend("top",                             # Add a legend to the plot
       legend=c("0","1","2","3","4"),          # Text for the legend
       fill=col,                               # Fill for boxes of the legend
       title="Rubric Score",
       bty="n",
       cex = 0.75,
       horiz = TRUE)                           # Fill for boxes of the legend
dev.off()
@
\includegraphics[width=\columnwidth,viewport = 30 0 288 288]{./figure/barplot}
\protect\caption{A barplot showing the distribution of rubric scores broken down by semester.}
\label{fig:barplot}
\end{figure}

% ANOVA TABLE INSERTED HERE
\begin{center}
<<anova, echo=FALSE, results='asis'>>=
myModel <- lm(SCI1 ~ Semester, data = myData)

library(xtable)
tempTable <- (xtable(anova(myModel),
caption="One-way ANOVA analysis of scores by semester",
label="tab:anova", type="latex"))
print(tempTable, caption.placement="top")
@
\end{center}

\subsection{Meta-analysis}
Meta-analysis of the student performance was performed using R \citep{TQMP11-1-37}. This analysis resulted in a weighted average of rubric scores. This value was calculated using formula \ref{eq:weightX}. The value X\textsubscript{i} average rubric scores for the semesters, while P\textsubscript{i} is the weighting factor (student enrollment).

\begin{equation}
\bar{X}_w = \frac{\sum X_i P_i}{\sum P_i}
\label{eq:weightX}
\end{equation}

The confidence interval for the weighted mean was calculated using the weighted variance. However, the weighted variance is actually not simple to calculate. Several different methods have been compared to bootstrapping \citep{Gatz1995a}. The most accurate method was initially described by Cochran \citep{Cochran1977} and that one was used in this study. The calculation to obtain the weighted variance is shown in formula \ref{eq:weightV}.

\begin{equation}
\begin{split}
(SEM_w)^2 = \frac{n}{(n-1)(\sum P_i)^2}\big[ \sum(P_i X_i - \bar{P}\bar{X}_w)^2 \\
- 2\bar{X}_w \sum(P_i - \bar{P})(P_i X_ i - \bar{P} \bar{X}_w) + \bar{X}_w^2 \sum(P_i - \bar{P})^2 \big]
\label{eq:weightV}
\end{split}
\end{equation}


% INSERT FOREST PLOT HERE
\begin{figure*}[htb]\centering % Using \begin{figure*} makes the figure take up the entire width of the page
<<forest, echo=FALSE, message=FALSE, warning=FALSE, results='hide'>>=
myData$SCI1 <- as.numeric(myData$SCI1)

dataTable <- myData %>%
	group_by(Order) %>%
	summarise(n = length(SCI1), mean = mean(SCI1), lower = mean(SCI1)-(1.96*sd(SCI1)/sqrt(length(SCI1))), upper = mean(SCI1)+(1.96*sd(SCI1)/sqrt(length(SCI1))))
dataTable$Order <- NULL
myWeighted <- weighted.var.se(dataTable$mean,dataTable$n)
dataTable$n <- NULL
dataTable <- rbind(dataTable,myWeighted)
nullHeadings <- c(NA,NA,NA)
dataTable <- rbind(nullHeadings,dataTable)

textTable <- myData %>%
	group_by(Order) %>%
	summarize(Semester = Semester[1], Prefix = Prefix[1], Level = Level[1], Outcome = "SCI1", N = length(SCI1), Mean = format(round(mean(SCI1),digits=2),nsmall=2))
textTable$Order <- NULL
textTable$Semester <- as.character(textTable$Semester)
textTable$Prefix <- as.character(textTable$Prefix)
textTable$Level <- as.character(textTable$Level)
headings <- c("Semester","Prefix","Level","Outcome","N","Mean")
textTable <- rbind(headings,textTable)
theSummary <- c("Weighted average",NA,NA,NA,NA,myWeighted)
textTable <- rbind(textTable,theSummary)

align <- c("c","c","c","c","c","c")

pdf("./figure/forest.pdf", width=8.0, height=4.0)
forestplot(textTable, dataTable,
	   new_page = FALSE,                             # Image on one page
	   is.summary=c(TRUE,rep(FALSE,13),TRUE),        # Bold for heading and summary lines
	   boxsize = .3,                                 # Set symbol size
	   xlog=FALSE,                                   # Linear scale
	   xticks = c(0,1,2,3,4),                        # Ticks at the rubric values
	   zero = 2.6,                                   # Set threshold value
	   grid = gpar(lty=3, col="#333333", lwd=1.25),  # Make vertical lines gray dots
	   xlab = "\nMean rubric score Â± 95% CI",        # Label x-axis
	   #title = "Performance on Scientific Understanding Outcome #1 Based Upon Lecture Exam 1",
	   align = align,                                # Center all text columns in table
	   colgap = unit(4, 'mm'),                       # Tighten up the columns
	   graphwidth = unit(90, 'mm'),                  # Make the plot 80mm wide
	   graph.pos=ncol(textTable),                    # Move average values after the plot
	   hrzl_lines = TRUE,                            # Add horizontal lines
	   txt_gp = fpTxtGp(label=gpar(cex=.75), xlab = gpar(cex=0.75), ticks = gpar(cex=0.75)),
	   col=fpColors(box="firebrick",line="black", summary="firebrick", zero="gray50"))
dev.off()
@
\includegraphics[width=\textwidth]{./figure/forest}
\protect\caption{A forest plot of the average scores for each semester with a weighted mean estimate for the entire period investigated. Error bars indicate the 95\% confidence intervals.}
\label{fig:forest}
\end{figure*}

% CALCULATE WEIGHTED T-TEST
<<weightedT, echo=FALSE, message=FALSE, warning=FALSE, results='asis'>>=
averages <- myData %>%
	group_by(Order) %>%
	summarise(n = length(SCI1), mean = mean(SCI1))

weightedT <- wtd.t.test(averages$mean, 2.6, averages$n)
@

A forest plot of the meta-analysis is shown in Figure \ref{fig:forest}. In this representation, each semester is illustrated as a separate line. The mean and 95\% confidence intervals for each semester are plotted in the right panel and their associated meta-data are given in the table to the left. The weighted average of all the data is plotted at the bottom of the figure. The width of the diamond indicates the 95\% confidence interval.

The rubric scale can be conceptually divided into five areas as shown in Table \ref{tab:regions}. Of the \Sexpr{max(myData$Order)} semesters, \Sexpr{sum(averages$mean >= 2.6)} fell in the proficient range, \Sexpr{sum(averages$mean >= 1.8 & averages$mean < 2.6)} fell in the developing range, and \Sexpr{sum(averages$mean < 1.8)} fell in the beginning range. The weighted mean score, \Sexpr{myWeighted[1]}, was not significantly different from the threshold of competence as judged by a weighted, one-factor, two-tailed t-test (t=\Sexpr{round(weightedT$coefficients[1],2)}, df=\Sexpr{weightedT$coefficients[2]}, p=\Sexpr{round(weightedT$coefficients[3],2)}). We can conclude that the weighted average score is practically equivalent to the competency threshold score.

\begin{table}[hbt]
\caption{Interpretation of average rubric scores}
\centering
\begin{tabular}{c c}
\textbf{Average score} & \textbf{Interpretation}   \\
\hline
0.00 to 0.99   &   Unsatisfactory                                \\
1.00 to 1.79   &   Beginning                                     \\
1.80 to 2.59   &   Developing                                    \\
2.60 to 3.39   &   Proficient                                    \\
3.40 to 4.00   &   Advanced                                      \\
\end{tabular}
\label{tab:regions}
\end{table}


%---------------------------
%>>>>>>> DISCUSSION  <<<<<<<
%---------------------------
\section{Discussion}
%\addcontentsline{toc}{section}{Results and Discussion} % Adds this section to the table of contents

A novel approach for the collection, aggregation, analysis, and reporting of General Education assessment data has been developed. Computationally reproducible reports can easily be generated and distributed to improve the program over time. A meta-analysis of data collected from a 200-level Biology course was used as a proof-of-concept.

Over a span of \Sexpr{max(myData$Order)} semesters, \Sexpr{round(sum(averages$mean >= 2.6)/length(averages$mean)*100,1)}\% of courses had mean scores considered to be proficient. Of all students in all semesters, \Sexpr{round(sum(myData$SCI1 >= 3)/length(myData$SCI1)*100,1)}\% met or exceeded the competence threshold. From these data it is inferred that the students meet (just barely) the threshold of competence.

\subsection{Faculty feedback}
This report will be distributed to members of the General Education Committee, Academic Senate, and the Department of Biological Sciences.  These individuals will be asked to provide their comments, suggestions, and concerns about this report and the processes involved in its creation. What thoughts do you have about:

\begin{itemize}[noitemsep]
\item The data provenance plan?
\item The format of this report?
\item The content of this report?
\item The utility of the meta-analysis?
\item The public release of assessment results?
\item Any other topics you can think of?
\end{itemize}

\subsection{Plan of action}
After analyzing the data and considering the comments provided in the faculty feedback, the relevant General Education sub-committee members will make one or more recommendations for future work. Some of the possible actions could include:
\begin{itemize}[noitemsep] % [noitemsep] removes whitespace between the items for a compact look
\item No modifications -- continue to gather data
\item Convene a training session to get better inter-course reliability
\item Suggest modifications to the types of assignments that are used
\item Suggest modifications to which data workbooks are used
\item Suggest that instructors consider modifying the scope or sequence of instruction
\item Modify the learning outcomes themselves
\item Modify the competency as a whole
\end{itemize}

%---------------------------
%>>>>> ACKNOWLEDGMENTS <<<<<
%---------------------------
\phantomsection
\section*{Acknowledgments} % The \section*{} command stops section numbering
\addcontentsline{toc}{section}{Acknowledgments} % Adds this section to the table of contents

This report was based off of a \LaTeX{} template created by Mathias Legrand. The original file can be accessed at: \\
\href{http://www.latextemplates.com/template/stylish-article}{http://www.latextemplates.com/template/stylish-article}. \\
The valuable contributions made by the members of the General Education Committee, Academic Senate, and Department of Biological Sciences are also greatly appreciated.

%---------------------------
%>>>>>>> REFERENCES  <<<<<<<
%---------------------------
\phantomsection
\printbibliography[title={References},heading=bibintoc]


%----------------------------------------------------------------------------------------

\end{document}
